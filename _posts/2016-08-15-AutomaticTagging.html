---
layout: default
title: Aumomatic Posts Tagging
---
<p>假设的场景是已有一系列标签（如，上市，破产），需要将文章归类到对应的标签下面。</p>
<br/>
<h3>1. 使用Latent Dirichlet Allocation (LDA) </h3>
<p>LDA 是一种无监督机器学习算法，这样可不用给训练用的语料库加标签。但是LDA的输出是一个标签列表，列出了它自动生成的标签的概率。这些自动生成的
标签跟我们所需要的标签是不同的，所以需要设计一个映射函数来最终给文章打上标签。这个映射函数有一些细节需要注意，比如如何映射判断目标文章不属于
我们所有的标签。</p>

<h3>2. 使用Neural Network </h3>
<p>问题的关键是如何给爬取的文章加标签来学习。 </p>
<p>(1). 需要人工介入，基本想法是收集标签数量*N的文章，一般标签数量应该不会太多，这样如果有十个标签且设定N=100，那么就是一千篇文章，一个人两天左右应该就能标记完
。然后事情就比较简单了，直接搭一个神经网络，最后一层是softmax，训练一下就可以了。如果精度不够就加深度，然后多爬一些文章手工打标签，如果有
两三个人，花一、两周时间，应该能够标记足够多的文章了。</p>
<p>(2). 思路是先用Recurrent Neural Network(RNN)学习一个语言模型，这样可以把一个句子表达成为定长的vector。然后把一片文章的所有句子转化为一个
定长的vector，再对每个vector进行PCA主成分分析，然后计算主成分跟标签的vector表示的相关性，相关度高的就打上对应的标签。我目前没有看到对语言
进行主成分分析的文章，所以这个方法需要试了才知道效果。</p>

<h3>3. 关键字匹配</h3>
<p>这个算法比较简单，主要是对关键字的维护。制定一个二维列表，第一位存储标签，第二位存储标签对应的常见关键字，这个可以也可以通过爬很多
网页，对出现了标签关键字的网页的高频词进行统计得到。然后判断的过程就是把一篇新的文章对每个标签和起对应的关键字scan一遍，根据制定的likelyhood
函数（比如可以是带权重的匹配次数的多项式的和对文本长度做nomralization）选择最近似的标签。</p>
