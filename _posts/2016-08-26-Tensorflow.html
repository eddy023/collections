---
layout: default
title: Tensorflow
---
<h3>1. Introduction</h3>

<h3>2. An Example</h3>
<p style="color:red">import tensorflow as tf</p>
<p>Create an session</p>
<p style="color:red">sess = tf.InteractiveSession()</p>
<p>Create holders for input and output, holder is a class to represent data of unknown dimension before trainning</p>
<p style="color:red">x = tf.placeholder(tf.float32, shape=[None, 784])</p>
<p style="color:red">y_ = tf.placeholder(tf.float32, shape=[None, 10])</p>
<p>Create variables for parameters, dimension of paramters is decided by the graph of a network, so it's initially known</p>
<p style="color:red">W = tf.Variable(tf.zeros([784,10]))</p>
<p style="color:red">b = tf.Variable(tf.zeros([10]))</p>
<p>Variables should be initiated before used in session</p>
<p style="color:red">sess.run(tf.initialize_all_variables())</p>
<p>The regression model, "tf.matmul(x,W) + b" produces a k-demension vector (dimension of the output) and the softmax outputed them in a probability form</p>
<p style="color:red">y = tf.nn.softmax(tf.matmul(x,W) + b)</p>
<p>Cross entropy evaluates the likehood between "y" and the label "y_", which is the cost function in fact</p>
<p style="color:red">cross_entropy = tf.reduce_mean(-tf.reduce_sum(y_ * tf.log(y), reduction_indices=[1]))</p>
<p>Use gradient descent to minimize the cross entropy</p>
<p style="color:red">train_step = tf.train.GradientDescentOptimizer(0.5).minimize(cross_entropy)</p>

<h3>3. Tensorflow Components</h3>
<h4>3.1. Graph</h4>
<p>A "Graph" contains a set of ["Operation"](../../api_docs/python/framework.md#Operation) objects, which represent units of computation; and ["Tensor"](../../api_docs/python/framework.md#Tensor) objects, which represent the units of data that flow between operations. A default "Graph" is always registered, and accessible by calling ["tf.get_default_graph()"](../../api_docs/python/framework.md#get_default_graph). To add an operation to the default graph, simply call one of the functions that defines a new "Operation", e.g.:
<p style="color:red">c = tf.constant(4.0)</p>
<p style="color:red">assert c.graph is tf.get_default_graph()</p>
<p>Another typical usage involves the ["Graph.as_default()"](../../api_docs/python/framework.md#Graph.as_default) context manager, which overrides the current default graph for the lifetime of the context:
<p style="color:red">g = tf.Graph()</p>
<p style="color:red">with g.as_default():</p>
<p>Define operations and tensors in "g"</p>
<p style="color:red">  c = tf.constant(30.0)</p>
<p style="color:red">  assert c.graph is g</p>
<p>Important note: Graph class *is not* thread-safe for graph construction. All operations should be created from a single thread, or external synchronization must be provided. Unless otherwise specified, all methods are not thread-safe.</p>
<p>A "Graph" instance supports an arbitrary number of "collections" that are identified by name. For convenience when building a large graph, collections can store groups of related objects: for example, the "tf.Variable" uses a collection (named ["tf.GraphKeys.VARIABLES"](../../api_docs/python/framework.md#GraphKeys)) for all variables that are created during the construction of a graph. The caller may define additional collections by specifying a new name.<p>
<h4>3.2. Operation</h4>
<p>An "Operation" is a node in a TensorFlow "Graph" that takes zero or more "Tensor" objects as input, and produces zero or more "Tensor" objects as output. Objects of type "Operation" are created by calling a Python op constructor (such as ["tf.matmul()"](../../api_docs/python/math_ops.md#matmul)) or ["Graph.create_op()"](../../api_docs/python/framework.md#Graph.create_op). For example "c = tf.matmul(a, b)" creates an "Operation" of type "MatMul" that takes tensors "a" and "b" as input, and produces "c" as output. After the graph has been launched in a session, an "Operation" can be executed by passing it to ["Session.run()"](../../api_docs/python/client.md#Session.run). "op.run()" is a shortcut for calling "tf.get_default_session().run(op)".
<h4>3.3. Tensor</h4>
<p>#A "Tensor" is a symbolic handle to one of the outputs of an 'Operation'. It does not hold the values of that operation's output, but instead provides a means of computing those values in a TensorFlow ["Session"](../../api_docs/python/client.md#Session). The tensor class has two primary purposes:</p>
<p>  1. A "Tensor" can be passed as an input to another "Operation". This builds a dataflow connection between operations, which enables TensorFlow to execute an entire "Graph" that represents a large, multi-step computation.</p>
<p>  2. After the graph has been launched in a session, the value of the "Tensor" can be computed by passing it to ["Session.run()"](../../api_docs/python/client.md#Session.run). "t.eval()" is a shortcut for calling "tf.get_default_session().run(t)".</p>
<p>  In the following example, "c", "d", and "e" are symbolic "Tensor" objects, whereas "result" is a numpy array that stores a concrete value:
<p>  Build a dataflow graph:</p>
<p style="color:red">  c = tf.constant([[1.0, 2.0], [3.0, 4.0]])</p>
<p style="color:red">  d = tf.constant([[1.0, 1.0], [0.0, 1.0]])</p>
<p style="color:red">  e = tf.matmul(c, d)</p>
<p>Check the construction function of class tensor, we can see a tensor would maintain a reference to an operation. </p>
<p style="color:red"></p>
<p style="color:red"></p>

<h3>4. Mechanism</h3>
<p>Describing a model with tensorflow, it's always based on a graph, no matter the default one or newly created one. With a graph, planceholders, variables and operations created will be attach to it and given to the C++ kernel to actually performing the trainning or prediction. A example is given below to show a graph strcuture. After we run a few lines of code, we print the content of a graph.</p>
<textarea style="color:red" rows="10" cols="40">
import tensorflow as tf
sess = tf.InteractiveSession()
x = tf.placeholder(tf.float32, shape=[None, 784])
y_ = tf.placeholder(tf.float32, shape=[None, 10])
W = tf.Variable(tf.zeros([784,10]))
b = tf.Variable(tf.zeros([10]))
y = tf.nn.softmax(tf.matmul(x,W) + b)
for i in tf.get_default_graph().get_operations():
    print(i)
</textarea>
<br/>
<textarea style="color:green" rows="508" cols="40">
name: "Placeholder"
op: "Placeholder"
attr {
  key: "dtype"
  value {
    type: DT_FLOAT
  }
}
attr {
  key: "shape"
  value {
    shape {
    }
  }
}

name: "Placeholder_1"
op: "Placeholder"
attr {
  key: "dtype"
  value {
    type: DT_FLOAT
  }
}
attr {
  key: "shape"
  value {
    shape {
    }
  }
}

name: "zeros"
op: "Const"
attr {
  key: "dtype"
  value {
    type: DT_FLOAT
  }
}
attr {
  key: "value"
  value {
    tensor {
      dtype: DT_FLOAT
      tensor_shape {
        dim {
          size: 784
        }
        dim {
          size: 10
        }
      }
      float_val: 0.0
    }
  }
}

name: "Variable"
op: "Variable"
attr {
  key: "container"
  value {
    s: ""
  }
}
attr {
  key: "dtype"
  value {
    type: DT_FLOAT
  }
}
attr {
  key: "shape"
  value {
    shape {
      dim {
        size: 784
      }
      dim {
        size: 10
      }
    }
  }
}
attr {
  key: "shared_name"
  value {
    s: ""
  }
}

name: "Variable/Assign"
op: "Assign"
input: "Variable"
input: "zeros"
attr {
  key: "T"
  value {
    type: DT_FLOAT
  }
}
attr {
  key: "_class"
  value {
    list {
      s: "loc:@Variable"
    }
  }
}
attr {
  key: "use_locking"
  value {
    b: true
  }
}
attr {
  key: "validate_shape"
  value {
    b: true
  }
}

name: "Variable/read"
op: "Identity"
input: "Variable"
attr {
  key: "T"
  value {
    type: DT_FLOAT
  }
}
attr {
  key: "_class"
  value {
    list {
      s: "loc:@Variable"
    }
  }
}

name: "zeros_1"
op: "Const"
attr {
  key: "dtype"
  value {
    type: DT_FLOAT
  }
}
attr {
  key: "value"
  value {
    tensor {
      dtype: DT_FLOAT
      tensor_shape {
        dim {
          size: 10
        }
      }
      float_val: 0.0
    }
  }
}

name: "Variable_1"
op: "Variable"
attr {
  key: "container"
  value {
    s: ""
  }
}
attr {
  key: "dtype"
  value {
    type: DT_FLOAT
  }
}
attr {
  key: "shape"
  value {
    shape {
      dim {
        size: 10
      }
    }
  }
}
attr {
  key: "shared_name"
  value {
    s: ""
  }
}

name: "Variable_1/Assign"
op: "Assign"
input: "Variable_1"
input: "zeros_1"
attr {
  key: "T"
  value {
    type: DT_FLOAT
  }
}
attr {
  key: "_class"
  value {
    list {
      s: "loc:@Variable_1"
    }
  }
}
attr {
  key: "use_locking"
  value {
    b: true
  }
}
attr {
  key: "validate_shape"
  value {
    b: true
  }
}

name: "Variable_1/read"
op: "Identity"
input: "Variable_1"
attr {
  key: "T"
  value {
    type: DT_FLOAT
  }
}
attr {
  key: "_class"
  value {
    list {
      s: "loc:@Variable_1"
    }
  }
}

name: "zeros_2"
op: "Const"
attr {
  key: "dtype"
  value {
    type: DT_FLOAT
  }
}
attr {
  key: "value"
  value {
    tensor {
      dtype: DT_FLOAT
      tensor_shape {
        dim {
          size: 784
        }
        dim {
          size: 10
        }
      }
      float_val: 0.0
    }
  }
}

name: "Variable_2"
op: "Variable"
attr {
  key: "container"
  value {
    s: ""
  }
}
attr {
  key: "dtype"
  value {
    type: DT_FLOAT
  }
}
attr {
  key: "shape"
  value {
    shape {
      dim {
        size: 784
      }
      dim {
        size: 10
      }
    }
  }
}
attr {
  key: "shared_name"
  value {
    s: ""
  }
}

name: "Variable_2/Assign"
op: "Assign"
input: "Variable_2"
input: "zeros_2"
attr {
  key: "T"
  value {
    type: DT_FLOAT
  }
}
attr {
  key: "_class"
  value {
    list {
      s: "loc:@Variable_2"
    }
  }
}
attr {
  key: "use_locking"
  value {
    b: true
  }
}
attr {
  key: "validate_shape"
  value {
    b: true
  }
}

name: "Variable_2/read"
op: "Identity"
input: "Variable_2"
attr {
  key: "T"
  value {
    type: DT_FLOAT
  }
}
attr {
  key: "_class"
  value {
    list {
      s: "loc:@Variable_2"
    }
  }
}

name: "zeros_3"
op: "Const"
attr {
  key: "dtype"
  value {
    type: DT_FLOAT
  }
}
attr {
  key: "value"
  value {
    tensor {
      dtype: DT_FLOAT
      tensor_shape {
        dim {
          size: 10
        }
      }
      float_val: 0.0
    }
  }
}

name: "Variable_3"
op: "Variable"
attr {
  key: "container"
  value {
    s: ""
  }
}
attr {
  key: "dtype"
  value {
    type: DT_FLOAT
  }
}
attr {
  key: "shape"
  value {
    shape {
      dim {
        size: 10
      }
    }
  }
}
attr {
  key: "shared_name"
  value {
    s: ""
  }
}

name: "Variable_3/Assign"
op: "Assign"
input: "Variable_3"
input: "zeros_3"
attr {
  key: "T"
  value {
    type: DT_FLOAT
  }
}
attr {
  key: "_class"
  value {
    list {
      s: "loc:@Variable_3"
    }
  }
}
attr {
  key: "use_locking"
  value {
    b: true
  }
}
attr {
  key: "validate_shape"
  value {
    b: true
  }
}

name: "Variable_3/read"
op: "Identity"
input: "Variable_3"
attr {
  key: "T"
  value {
    type: DT_FLOAT
  }
}
attr {
  key: "_class"
  value {
    list {
      s: "loc:@Variable_3"
    }
  }
}

name: "init"
op: "NoOp"
input: "^Variable/Assign"
input: "^Variable_1/Assign"
input: "^Variable_2/Assign"
input: "^Variable_3/Assign"

name: "MatMul"
op: "MatMul"
input: "Placeholder"
input: "Variable_2/read"
attr {
  key: "T"
  value {
    type: DT_FLOAT
  }
}
attr {
  key: "transpose_a"
  value {
    b: false
  }
}
attr {
  key: "transpose_b"
  value {
    b: false
  }
}

name: "add"
op: "Add"
input: "MatMul"
input: "Variable_3/read"
attr {
  key: "T"
  value {
    type: DT_FLOAT
  }
}

name: "Softmax"
op: "Softmax"
input: "add"
attr {
  key: "T"
  value {
    type: DT_FLOAT
  }
}
</textarea>
<p>We can see a graph use a 4-tuple (i.e. name, op, input, and attr) structure to describe an entity. The name is automatically given based on the op which is the name of a variable, placeholder or operation. The input is the name of another entity. The attr provides the information of entity attributions, e.g., data dimension, value, and value type. An entity may contain several inputs or attrs.</p>

