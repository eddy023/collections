---
layout: default
title: Tensorflow
---
<h3>1. Introduction</h3>

<h3>2. An Example</h3>
<p style="color:red">import tensorflow as tf</p>
<p>#Create an session</p>
<p style="color:red">sess = tf.InteractiveSession()</p>
<p>#Create holders for input and output, holder is a class to represent data of unknown dimension before trainning</p>
<p style="color:red">x = tf.placeholder(tf.float32, shape=[None, 784])</p>
<p style="color:red">y_ = tf.placeholder(tf.float32, shape=[None, 10])</p>
<p>#Create variables for parameters, dimension of paramters is decided by the graph of a network, so it's initially known</p>
<p style="color:red">W = tf.Variable(tf.zeros([784,10]))</p>
<p style="color:red">b = tf.Variable(tf.zeros([10]))</p>
<p>#Variables should be initiated before used in session</p>
<p style="color:red">sess.run(tf.initialize_all_variables())</p>
<p>#The regression model, "tf.matmul(x,W) + b" produces a k-demension vector (dimension of the output) and the softmax outputed them in a probability form</p>
<p style="color:red">y = tf.nn.softmax(tf.matmul(x,W) + b)</p>
<p>#Cross entropy evaluates the likehood between "y" and the label "y_", which is the cost function in fact</p>
<p style="color:red">cross_entropy = tf.reduce_mean(-tf.reduce_sum(y_ * tf.log(y), reduction_indices=[1]))</p>
<p>#Use gradient descent to minimize the cross entropy</p>
<p style="color:red">train_step = tf.train.GradientDescentOptimizer(0.5).minimize(cross_entropy)</p>
<p>#We can see a train_step is an operation (tensor) which keeps an inner reference to cross_entropy; cross_entropy again represents operations on y_ and y which is a tensor for softmax operation. This is how operations are embeded sequentially and lastly get executed in a session.</p>
<p>#A "Tensor" is a symbolic handle to one of the outputs of an 'Operation'. It does not hold the values of that operation's output, but instead provides a means of computing those values in a TensorFlow [`Session`](../../api_docs/python/client.md#Session). The tensor class has two primary purposes:</p>
<p>  1. A `Tensor` can be passed as an input to another `Operation`. This builds a dataflow connection between operations, which enables TensorFlow to execute an entire `Graph` that represents a large, multi-step computation.</p>
<p>  2. After the graph has been launched in a session, the value of the "Tensor" can be computed by passing it to [`Session.run()`](../../api_docs/python/client.md#Session.run). "t.eval()" is a shortcut for calling "tf.get_default_session().run(t)".</p>
<p>  In the following example, "c", "d", and "e" are symbolic "Tensor" objects, whereas "result" is a numpy array that stores a concrete value:
<p>  Build a dataflow graph:</p>
<p>  c = tf.constant([[1.0, 2.0], [3.0, 4.0]])</p>
<p>  d = tf.constant([[1.0, 1.0], [0.0, 1.0]])</p>
<p>  e = tf.matmul(c, d)</p>
<p style="color:red"></p>
<p style="color:red"></p>
<p style="color:red"></p>
