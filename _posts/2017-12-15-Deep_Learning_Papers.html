---
layout: default
title: Deep Learning Papers
---
<h2>{{ page.title }}</h2>

<head>
<style type="text/css">
table {
    display: table;
    border-collapse: collapse;
    border-spacing: 0px;
    border-color: grey;
    border: 1px solid black;
    cell-spacing: 0;
}
table, th, td {
    padding:.1cm .1cm .1cm .1cm;
    border: 1px solid grey;
    vertical-align: top;
}
th
{
    bgcolor: grey;
}
a {
    color: blue;
    text-decoration: none;
}
td {
    word-spacing: 2px;
    text-align: left;
}
.paperTitle{
    font-size:23px
    color: blue;
}
</style>
</head>

<!--<table margin-top="15px" border-collapse="collapse" border="1px solid #aaa" width="100%" cellspacing="0.1" cellpadding="20">-->
<!--<table style = "margin-top: 15px; border-collapse: collapse; border: 1px solid #aaa; width: 100%;">-->
<table>
  <tbody>
    <tr>
      <th width="20%">Paper</th>
      <th width="5%">Year</th>
      <th width="15%">Author</th>
      <th width="10%">Keywords</th>
      <th width="45%">Notes</th>
    </tr>
      
     <tr>
      <td class = "paperTitle"><a href="http://yann.lecun.com/exdb/publis/pdf/lecun-bengio-95a.pdf">
                   Convolutional networks for images, speech, and time series</a></td>
      <td>1998</td>
      <td>Yann LeCun, Yoshua Bengio</td>
      <td>convoluational network</td>
      <td></td>
    </tr>
    </tr>

     <tr>
      <td class = "paperTitle"><a href="https://research.cs.washington.edu/istc/lfb/paper/cvpr12.pdf">
                   Rgb-(d) scene labeling: Features and algorithms</a></td>
      <td>2012</td>
      <td></td>
      <td>scene labeling</td>
      <td>
          <p>Goal: indoor scene labeling</p>
          <p>Gap:  large variations of scene types, lack of distinctive features, and poor illumination</p>
          <p>Method: combines rich RGB-D features and contextual models using MRFs and hierarchical segmentation.</p>
          <p>Notes: use kernel descriptor(2, 3), aggregate over superpixel </p>
          <p>[RGB-D sensors, MRF (markov random fields, 8, 16, 18, 32), CRF(conditional random fields), 
              <a href="https://infoscience.epfl.ch/record/177415">superpixel</a>, multiple segmentations(6,16,27), 
              hierarchical segmentations(21,23), ]</p>
      </td>
    </tr>
    
    <tr>
      <td class = "paperTitle"><a href="http://yann.lecun.com/exdb/publis/pdf/farabet-pami-13.pdf">
                   Learning hierarchical features for scene labeling</a></td>
      <td>2013</td>
      <td>Cle ÃÅment Farabet, Camille Couprie, Laurent Najman, Yann LeCun</td>
      <td>scene labeling</td>
      <td>
          <p>Goal: </p>
      </td>
    </tr>

    <tr>
      <td class = "paperTitle"><a href="https://www.inf.ethz.ch/personal/ladickyl/road_bmvc09.pdf">
                   Combining appearance and structure from motion features for road scene understanding</a></td>
      <td>2013</td>
      <td></td>
      <td></td>
      <td>
          <p>Goal: </p>
      </td>
    </tr>

    <tr>
      <td class = "paperTitle"><a href="https://people.eecs.berkeley.edu/~jonlong/long_shelhamer_fcn.pdf">
                   Fully convolutional networks for semantic segmentation</a></td>
      <td></td>
      <td></td>
      <td></td>
      <td>
          <p>Goal: </p>
          <p>[overfeat(32)]</p>
          <p>{can improve the dense prediction policy (to beat deconvolution)}</p>
      </td>
    </tr>

    <tr>
      <td class = "paperTitle"><a href="https://people.eecs.berkeley.edu/~jonlong/long_shelhamer_fcn.pdf">
                   Fully convolutional networks for semantic segmentation</a></td>
      <td></td>
      <td></td>
      <td></td>
      <td>
          <p>Goal: </p>
          <p>[overfeat(32)]</p>
          <p>{can improve the dense prediction policy (to beat deconvolution)}</p>
      </td>
    </tr>

    <tr>
      <td class = "paperTitle"><a href="https://arxiv.org/pdf/1606.00915.pdf">
                   Semantic image segmentation with deep convolutional nets and fully connected crfs</a></td>
      <td></td>
      <td></td>
      <td></td>
      <td>
          <p>Goal: </p>
      </td>
    </tr>

    <tr>
      <td class = "paperTitle"><a href="https://arxiv.org/pdf/1312.6229.pdf">
                   Overfeat: Integrated recognition, localization and detection using convolutional networks</a></td>
      <td></td>
      <td></td>
      <td></td>
      <td>
          <p>Goal: </p>
      </td>
    </tr>

    <tr>
      <td class = "paperTitle"><a href="http://yann.lecun.com/exdb/publis/pdf/lecun-89e.pdf">
                   Backpropagation applied to hand-written zip code recognition</a></td>
      <td></td>
      <td></td>
      <td><p>leNet</p></td>
      <td>
          <p>Goal: </p>
      </td>
    </tr>

    <tr>
      <td class = "paperTitle"><a href="https://www.nvidia.cn/content/tesla/pdf/machine-learning/imagenet-classification-with-deep-convolutional-nn.pdf">
                   Imagenet classification with deep convolutional neural networks</a></td>
      <td></td>
      <td></td>
      <td><p>AlexNet</p></td>
      <td>
          <p>Goal: </p>
          <p>{should encode info into nn, not just use tons of weights to (simulate large number of dimensions of borders) filter/classify 
              objects, that would improve the real intelligence of network}</p>
          <p>[<a href="https://www.zhihu.com/question/24529483">momentum variable</a>, white decap]</p>
      </td>
    </tr>

    <tr>
      <td class = "paperTitle"><a href="https://arxiv.org/pdf/1409.1556.pdf">
                   Very deep convolutional networks for large-scale image recognition</a></td>
      <td></td>
      <td></td>
      <td></td>
      <td>
          <p>Goal: </p>
      </td>
    </tr>

    <tr>
      <td class = "paperTitle"><a href="https://www.cs.unc.edu/~wliu/papers/GoogLeNet.pdf">
                   Going deeper with convolutions</a></td>
      <td></td>
      <td></td>
      <td></td>
      <td>
          <p>Goal: </p>
      </td>
    </tr>

  </tbody>
</table>
