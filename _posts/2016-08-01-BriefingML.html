---
layout: default
title: A Quick Look into Machine Learning Algorithms
---

<script type="text/javascript" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>

<p style="font-style:italic">The scientist’s discoveries impose his own order on chaos, as the composer or painter imposes his.
<p style="text-align: right; font-style:italic">— Arthur Koestler</p>
<br />
<p style="font-size:24px; font-weight:bold">I. Introduction</p>
<p style="text-align:center"><img src="/collections/imgs/1-ml-model.png" alt="basic ml model" style="width:400px;height:300px;" /></p>
<p style="text-align:center; font-style:italic">Fig. 1-1 A basic model of machine learning algorithm</p>

<p>The above figure depicts the basic model of machine learning and can be interpreted using a simple math formula:</p>
<p>$$ y = h(\sum_{i=0}^n \theta_i \times x_i) $$</p>
<p>\(x\) and \(y\) are the input and output data of the model, collected beforehand or to be prected; 
\(h\) represents "hypothesis" and is partially embodied by \(theta\) which are the parameters to learn. 
For any known machine learning problem, people follow this basic model no matter how complicated their specific algorithm is.</p>
<p>The essence of this models lies in two aspects: 1) using given set of \(x\) and \(y\) to discover a coherent relation or 
mapping between the input and the output, which is the learning process on \(theta\); 2) using learnt \(theta\) and newly input \(x\)
to predict \(y\).</p>
<p> If during the learning process, \(y\) is not provided, the algorithm proposed for such problem is called unsupervised learning
, or supervised learning otherwise. Notably, another type of learning algorithm called reinforcement learning gains increasingly 
more attention of the public. Basically, "Reinforcement learning differs from standard supervised learning in that correct input/output 
pairs are never presented, nor sub-optimal actions explicitly corrected.", as I quote from wikipedia.</p>

<p>We will discuss several supervised and unpervised learning algorithms in this post, but temporarily not dig into reinforcement learning (RL), thus insteand we present a few RL applications below to gain some quick intuitives.</p>
<p style="text-align:center"><img src="/collections/imgs/1-shinkansen-cn.png" style="width:400px;height:300px;" /><img src="/collections/imgs/1-shinkansen-jp.png" style="width:400px;height:300px;" /></p>
<p style="text-align:center; font-style:italic">Fig. 1-2 Two different shapes of bullet trains</p>
<p style="text-align:center"><img src="/collections/imgs/1-robot-walk.png" style="width:400px;height:300px;" /><img src="/collections/imgs/1-quadriplane-fly.png" style="width:400px;height:300px;" /></p>
<p style="text-align:center; font-style:italic">Fig. 1-3 Robot walking and quadriplane flying</p>
<br/>
<p style="font-size:24px; font-weight:bold">II. Regession</p>
<br />
<p style="font-size:18px; font-style:italic">1. Linear Regression</p>
<p>Linear regression is oftenly used to trian a "mapping" to predict the value of a CONTINUOUS variable (e.g., temperature, housing price, visitors, etc). Given a set of data with some inherent linear structure, we try fitting a line into the "sparse data". The data look likes "regressing" into a line which could be straight, curve, or more complicated shape, depends on the model choosed. The gist is to seek balance between under-fitting and over-fitting of data. </p>
<p style="text-align:center"><img src="/collections/imgs/2-linear-regression.png" style="width:400px;height:300px;" /><img src="/collections/imgs/2-linear-regression2.png" style="width:400px;height:300px;" /></p>
<p style="text-align:center; font-style:italic; font-weight:bold">Fig. 2-1 Two examples of linear regression</p>
<p>In Fig. 2-1, the first sub-figure simply follows the model:</p>
<p>$$ y = \sum_{i=0}^n \theta_i \times x_i $$</p>
<p>For the sub-figure in the right, higher order features were introduced:</p>
<p>$$ y = \sum_{i=0}^n \theta_i \times x_i + \theta_i' \times x_i^2 + ... $$</p>
<p>\(n\) represents the number of features, e.g., house area, location, floor, etc. for hourse price prediction. Introducing higher order of them may help improve the prediction accuracy, but as having said, needs to trade between under-fitting and over-fitting</p>
<p>To fit the line to data, we need a criterion on how well the line is fitted and thus we need a cost function:</p>
<p>$$J(\theta) = \frac{1}{2m}\sum_{j=0}^m (\sum_{i=0}^n \theta_i \times x_i^{(j)} - y_j)^2 $$</p>
<p>\(m\) is the number of training data size, that is, the number of (\(x\), \(y\)) pairs.<p>
<br />
<p style="font-size:18px; font-style:italic; font-weight:bold">2. Logistical Regression</p>
<p>Logistical regression would learn a model to classify data into two groups (e.g., spam email filter). To do this, we apply a logistical or sigmoid function on the linear regression model, which "squashes" y's domain from (-inf,inf) to (0,1). We benefit from two aspects: 1) we can interpret the value of y in (0,1) as a probability variable to construct a cost functoin; 2) the logistical function is derivative in (-inf, inf) to be applied with optimzation algorithm. Actually, sigmoid function is believed as the simplest example of a log-linear model which presents a dozen favorable attributes.</p>
<p>$$ y = \frac{1}{1+e^{\theta^{T}X}} $$</p>
<p>In above logistical model, \(\theta\) and \(X\) are vectors and \(T\) is transpose.</p>
<p style="text-align:center"><img src="/collections/imgs/2-sigmoid-function.png" style="width:400px;height:300px;" /></p>
<p style="text-align:center; font-style:italic; font-weight:bold">Fig. 2-2 Logistical/Sigmoild function</p>
<br />
<p>$$ J(\theta) = -\left[ \sum_{i=1}^m y^{(i)} \log h_\theta(x^{(i)}) + (1-y^{(i)}) \log (1-h_\theta(x^{(i)})) \right] $$</p>
<p>\(J(\theta)\) is the cost function for logistical regression. It's simply deduced from take log-function on the likehood formula of \(y\)'s probablity.</p>

<p style="font-size:18px; font-style:italic; font-weight:bold">3. Under-fitting & Over-fitting</p>
<p>Overfitting occurs when a statistical model or machine learning algorithm captures the noise of the data. Intuitively, overfitting occurs when the model or the algorithm fits the data too well. Specifically, overfitting occurs if the model or algorithm shows low bias but high variance.  Overfitting is often a result of an excessively complicated model, and it can be prevented by fitting multiple models and using validation or cross-validation to compare their predictive accuracies on test data.</p>
<p>Underfitting occurs when a statistical model or machine learning algorithm cannot capture the underlying trend of the data.  Intuitively, underfitting occurs when the model or the algorithm does not fit the data well enough.  Specifically, underfitting occurs if the model or algorithm shows low variance but high bias.  Underfitting is often a result of an excessively simple model.</p>
<p>We employ two terms bias and variance to judge whether a learnt model is overfitting or underfitting. <a href="http://www.inf.ed.ac.uk/teaching/courses/mlsc/Notes/Lecture4/BiasVariance.pdf">"The Bias-Variance Tradeoff"</a> provides a detailed explanation on how they are deduced.</p>
<p style="text-align:center"><img src="/collections/imgs/2-fitting-problem.png" style="width:800px;height:600px;" /></p>
<p style="text-align:center; font-style:italic; font-weight:bold">Fig. 2-2 Under-/Over-fitting</p>
<p>In practical projects, we usually plot a figure according to training error and cross validation to reflect the bias and vairance. Read this <a href="">post</a> for details.</p>
<br />
<p style="font-size:18px; font-style:italic; font-weight:bold">4. Regularization</p>
<p>Regularization allows complex models to be trained on data sets of limited size without severe ovefitting, by limiting the effective model complexity.</p>
<p>$$ J(\theta) = \frac{1}{2m}(\sum_{i=1}^m(h_{\theta}(x^{(i)}-y^{(i)})^2 + \lambda\sum_{i=1}^n\theta_j^2) $$</p>
<p>\(m\) is the size of training data and \(n\) is the number of the paramter \theta.</p>
<br />
<p style="font-size:18px; font-style:italic; font-weight:bold">5. Parameter Learning </p>
<p>The learning process is to find the set of parameters \(\theta\) that minimize the cost functin. The cost function for linear and logistical regression are convex, hence we can apply a bunch of optimization algorithms to find an optimal value. A well known algorithm is Newton's method, but it involves calcuating inverse matrix which is computation resource intensive when come to large number of parameters, so we simply apply gradient descent of which the gist is to reduce the cost toward its gradient's direction step by step, till a criterion is met:</p>
<p>$$ \theta = \theta - \alpha \times \nabla_\theta J(\theta) = \theta - \alpha \sum_{j=0}^m (\sum_{i=0}^n \theta_i \times x_i^{(j)} - y_j) \cdot x $$</p>
<p>We use linear regression as a example and the cost function is the Euclidean distance between \(h(\theta)\) and \(y\); \(\alpha\) is the learning rate and in more advanced algorithm it would be automatically modulated to learn faster.</p>
<br />
<p style="font-size:18px; font-style:italic; font-weight:bold">6. Softmax and Cross Entropy</p>
<p>Logistical regression classfies target objects into two groups, and when come with more classes, we apply softmax regression for classification.</p>
<p>$$
h_\theta(x) =
\begin{bmatrix}
P(y = 1 | x; \theta) \\
P(y = 2 | x; \theta) \\
\vdots \\
P(y = K | x; \theta)
\end{bmatrix}
=
\frac{1}{ \sum_{j=1}^{K}{\exp(\theta^{(j)\top} x) }}
\begin{bmatrix}
\exp(\theta^{(1)\top} x ) \\
\exp(\theta^{(2)\top} x ) \\
\vdots \\
\exp(\theta^{(K)\top} x ) \\
\end{bmatrix}
$$</p>
<p>Here \(\theta^{(1)}, \theta^{(2)}, \ldots, \theta^{(K)} \in \Re^{n}\) are the parameters of our model. Notice that the term \(\frac{1}{ \sum_{j=1}^{K}{\exp(\theta^{(j)\top} x) } }\) normalizes the distribution, so that it sums to one.</p>
<p>$$
J(\theta) = - \left[ \sum_{i=1}^{m} \sum_{k=1}^{K}  1\left\{y^{(i)} = k\right\} \log \frac{\exp(\theta^{(k)\top} x^{(i)})}{\sum_{j=1}^K \exp(\theta^{(j)\top} x^{(i)})}\right]
$$</p>
<p>The cost function of softmax regression is usually called cross entropy, which is an idea from information theory.</p>
<p>Notice that this generalizes the logistic regression cost function, which could also have been written:</p>
<p>$$
\begin{align}
J(\theta) & = - \left[ \sum_{i=1}^m   (1-y^{(i)}) \log (1-h_{\theta}(x^{(i)})) + y^{(i)} \log h_{\theta}(x^{(i)}) \right] \\
& = - \left[ \sum_{i=1}^{m} \sum_{k=0}^{1} 1\left\{y^{(i)} = k\right\} \log P(y^{(i)} = k | x^{(i)}; \theta) \right]
\end{align}
$$</p>
<p>To train data with gradient descent method, firstly need to find the form of gradient of \(J(\theta)\):</p>
<p>$$
\nabla_{\theta^{(k)}} J(\theta) = - \sum_{i=1}^{m}{ \left[ x^{(i)} \left( 1\{ y^{(i)} = k\}  - P(y^{(i)} = k | x^{(i)}; \theta) \right) \right]  }
$$</p>
<p>Softmax regression is hugely useful, in deep nerual network, the last layer would usually adopt softmax regression to finally classify an object.</p>
<br />
<p style="font-size:24px; font-weight:bold">III. Clustering and SVM</p>

<br />
<p style="font-size:24px; font-weight:bold">IV. Baysian Model and Markov Process</p>

<br />
<p style="font-size:24px; font-weight:bold">V. Hidden Markov Process and EM Algorithm</p>

<br />
<p style="font-size:24px; font-weight:bold">VI. Nerual Network</p>
<br />
<p style="font-size:18px; font-style:italic; font-weight:bold">1. Representation</p>
<p>Neural networks were developed as a way to simulate networks of neurones.</p>
<p style="text-align:center"><img src="/collections/imgs/6-neuron.png" style="width:600px;height:350px;" /></p>
<p style="text-align:center; font-style:italic; font-weight:bold">Fig. 6-1 Structure of a Neuron</p>
<p>In below figure, we use a simple neural network to represent the logistical regression.<p>
<p style="text-align:center"><img src="/collections/imgs/6-logistical-regression.png" style="width:600px;height:350px;" /></p>
<p style="text-align:center; font-style:italic; font-weight:bold">Fig. 6-2 Logistical regression with NN</p>
<p>A typical neural network with input-, hidden- and output-layer is given below. We may use sigmoid function as the activiation function at all nodes. By activation, we mean the value which is computed and output by that node.</p>
<p style="text-align:center"><img src="/collections/imgs/6-basic-NN.png" style="width:600px;height:350px;" /></p>
<p style="text-align:center; font-style:italic; font-weight:bold">Fig. 6-3 A three-layer neural network</p>
<br />
<p style="font-size:18px; font-style:italic; font-weight:bold">2. Forward Propagation</p>
<p>Training a neural involves two phases per iteration, started with forwarding propagation:</p>
<p style="text-align:center"><img src="/collections/imgs/6-forward-p.png" style="width:700px;height:400px;" /></p>
<p style="text-align:center; font-style:italic; font-weight:bold">Fig. 6-4 Forward propagation</p>
<p>Here \(g\) is the activation function and \(a\) is the output or activated of a input.</p>
<br />
<p style="font-size:18px; font-style:italic; font-weight:bold">3. Backword Propagation</p>
<p>Back propagation basically takes the output you got from your network, compares it to the real value \(y\) and calculates how wrong the network was (i.e. how wrong the parameters were). It then, using the error you've just calculated, back-calculates the error associated with each unit from the preceding layer (i.e. layer L - 1). This goes on until you reach the input layer (where obviously there is no error, as the activation is the input). These "error" measurements for each unit can be used to calculate the partial derivatives, which gradient descent needs to minimize the cost function. We use the partial derivatives with gradient descent to try minimize the cost function and update all the \(\theta\) values. This repeats until gradient descent reports convergence.</p>
<p style="text-align:center"><img src="/collections/imgs/6-backward-p.png" style="width:750px;height:400px;" /></p>
<p style="text-align:center; font-style:italic; font-weight:bold">Fig. 6-5 Backward propagation</p>
<p>Read <a href="http://work.caltech.edu/slides/slides10.pdf">Caltech's</a> lecture slides for detailed explanation.</p>
<p style="text-align:center"><img src="/collections/imgs/6-bp-deduce.png" style="width:900px;height:500px;" /></p>
<p style="text-align:center; font-style:italic; font-weight:bold">Fig. 6-6 Derivation of \(\delta\)</p>

<br />
<p style="font-size:24px; font-weight:bold">VII. Convolutional Neural Network</p>
<p>A Convolutional Neural Network (CNN) is comprised of one or more convolutional layers (often with a subsampling step) and then followed by one or more fully connected layers as in a standard multilayer neural network. </p>
<p style="text-align:center"><img src="/collections/imgs/7-cnn_layer.png" style="width:600px;height:400px;" /></p>
<p style="text-align:center; font-style:italic; font-weight:bold">Fig. 7-1 The first layer of a CNN with pooling</p>
<p>At the convolutional layers, a set of feature detectors is employed to filter the input data (e.g., an image) to extract inherent features.</p>
<p style="text-align:center"><img src="/collections/imgs/7-convolution_schematic.gif" style="width:600px;height:400px;" /></p>
<p style="text-align:center; font-style:italic; font-weight:bold">Fig. 7-2 Convolved feature of an image</p>
<p>To be more intuitive, the below picture shows how a stack of features is combined into an image.<p>
<p style="text-align:center"><img src="/collections/imgs/7-features.png" style="width:800px;height:600px;" /></p>
<p style="text-align:center; font-style:italic; font-weight:bold">Fig. 7-3 Trainning on face images</p>
<p>Features are learnt layer by layer from bottom to the top and can be done with autoencoder or sparse coding.</p>
<p style="text-align:center"><img src="/collections/imgs/7-feature_layered.png" style="width:800px;height:600px;" /></p>
<p style="text-align:center; font-style:italic; font-weight:bold">Fig. 7-4 Learning feature hiearchies</p>
<p>Intuitively, after filter by a edge dector, an image may look like: </p>
<p style="text-align:center"><img src="/collections/imgs/7-edge-d.png" style="width:800px;height:300px;" /></p>
<p style="text-align:center; font-style:italic; font-weight:bold">Fig. 7-5 Before and after of filter by edge detector</p>
<p>Refer to <a href="http://ufldl.stanford.edu/tutorial/unsupervised/Autoencoders/">stanford's deep learning website</a> for details of autoencoder. Briefly, it's an unsupervised learning algorithm which use the input as the output. The hidden layer are features to learn. The weight matrix between the input layer and the hidder layer are the intended feature detectors.</p>
<p style="text-align:center"><img src="/collections/imgs/7-autoencoder.png" style="width:650px;height:600px;" /></p>
<p style="text-align:center; font-style:italic; font-weight:bold">Fig. 7-6 An example of autoencoder</p>
<p>Fig. 7-7 shows an end-to-end deep convolutional neural network. Note that the final layer applies softmax regression.</p>
<p style="text-align:center"><img src="/collections/imgs/7-cnn_arc.png" style="width:900px;height:400px;" /></p>
<p style="text-align:center; font-style:italic; font-weight:bold">Fig. 7-7 Demonstration of a deep CNN</p>

<br />
<p style="font-size:24px; font-weight:bold">VIII. Recurrent Neural Network</p>
<br />
<p style="font-size:18px; font-style:italic; font-weight:bold">1. Basic RNN Model</p>
<p>Unlike feed forward neural network, a recurrent neural network reuses the same set of parameters per iteration. This allows RNN maintain a dynamic state that suitable for dealing with variable length problems.</p>
<p style="text-align:center"><img src="/collections/imgs/8-RNN-1.png" style="width:350px;height:400px;" /><img src="/collections/imgs/8-RNN-2.png" style="width:550px;height:400px;" /></p>
<p style="text-align:center; font-style:italic; font-weight:bold">Fig. 8-1 An illustration of the structure of RNN</p>
<p>For a single time step, we have:</p>
<p>$$ h_{t} = \sigma(W_{hh} h_{t-1} + W_{hx} x_{t}) $$ </p>
<p>$$ y_{t} = softmax(W_{s} h_{t}) $$ </p>
<p>where \(W_{hh} \in R_{D_{h} \times R_{D_{h}}}, W_{hx} \in R_{D_{h} \times d} and W_(s) \in R_{|V| \times D_{h}} \)</p>
<p>The loss function of RNN is:</p>
<p>$$J(\theta) = -\frac{1}{T} \sum_{t=1}{T} \sum_{j=1}{|V|} y_{t,j} log y'_{t,j} $$</p>
<p>A basic RNN suffers the well known gradient vanishing/exploding problem which makes the trainig process pretty hard; refer to <a href="http://cs224d.stanford.edu/lectures/CS224d-Lecture8.pdf">stanford CS224d courser slides</a> for details. Generally, since the same set of weights are used, during back progagation to learn the parameters, the error signal may diminish to none or grow into a huge number that makes the parameters hard to converge. </p>

<br />
<p style="font-size:18px; font-style:italic; font-weight:bold">2. LSTM & GRU　Cell</p>
<p>To handle the gradient vanishging/exploding problem, a new type of neural cell is invented:</p>
<p style="text-align:center"><img src="/collections/imgs/8-lstm.png" style="width:450px;height:400px;" /></p>
<p style="text-align:center; font-style:italic; font-weight:bold">Fig. 8-2 A LSTM cell</p>

<br />
<p style="font-size:24px; font-weight:bold">IX. Dynamic Memory Network</p>

<br />
<p style="font-size:24px; font-weight:bold">X. Chatbot</p>
<br />
<p style="font-size:18px; font-style:italic; font-weight:bold">1. Language Modelling</p>
<p>A statistical language model is a probability distribution over sequences of words.Given such a sequence, say of length \(m\),
it assigns a probability \(P(w_{1},..., w_{m})\) to the whole sequence. Below some models to calculate the probability are
provided:</p>
<br/>
<p>a. Uni-gram</p>
<p>$$
\begin{align}
P(t_{1}t_{2}t_{3} \cdots t_{n}) & = P(t_{1})P(t_{2}|t_{1})P(t_{3}|t_{1}t_{2}) \cdots P(t_{n}|t_{1}t_{2} \cdots t_{n-1}) \\ & = P(t_{1})P(t_{2}) \cdots P(t_{n}) 
\end{align}
$$ </p>
<p>In the second step, it's assumed that each word is independent from each other.</p>
<br/>
<p>b. N-gram</p>
<p>$$ 
\begin{align}
P(t_{1}t_{2}t_{3} \cdots t_{n}) & =P(t_{1})P(t_{2}|t_{1})P(t_{3}|t_{1}t_{2}) \cdots P(t_{n}|t_{1}t_{2} \cdots t_{n-1}) \\ & =P(t_{1})P(t_{2}|t_{1}) \cdots P(t_{n}|t_{n-1}) 
\end{align}
$$ </p>
<p>The second step assumes (markov assumption) a 2-gram model which means the occurance of a word is solely dependent on its previous one. To calculate \(P(t_{n}|t_{1})\), simply count the times the pair appears in the training data and you can refer to these <a href="https://web.stanford.edu/class/cs124/lec/languagemodeling.pdf">slides</a> from Stanford for details.</p>
<p>$$ 
p(w_t \: | \: w_{t-1} , \cdots , w_{t-n+1}) = \dfrac{count(w_{t-n+1}, \cdots , w_{t-1},w_t)}{count({w_{t-n+1}, \cdots , w_{t-1}})}
$$ </p>
<p>We achieve the same objective using the well-known softmax layer in neural networks. We will take a closely look in the next sub-section.</p>
<p>$$ 
p(w_t \: | \: w_{t-1} , \cdots , w_{t-n+1}) = \dfrac{\text{exp}({h^\top v'_{w_t}})}{\sum_{w_i \in V} \text{exp}({h^\top v'_{w_i}})}
$$ </p>
<br/>
<p>c. Continuous space language model</p>
<p>Continuous space language models use continuous representations or embeddings of words to make their predictions.
Neural network based language models are an example but there are other varieties such as log-bilinear models.
Typically, neural net language models are constructed and trained as probabilistic classifiers that learn to predict a probability distribution
\(P(w_{t}|context) \forall \in V\). The network is trained to predict a probability distribution over the vocabulary, given some linguistic context.
This is done using standard neural network training algorithms such as stochastic gradient descent with backpropagation.It can use previous or future words to
make the prediction of the current words, or reversely, using the current word to learn the context.</p>
<p style="text-align:center"><img src="/collections/imgs/10-lm.png" style="width:400px;height:400px;" /></p>
<p style="text-align:center; font-style:italic; font-weight:bold">Fig. 10-1 A classic neural language model</p>
<p>The classic neural language model in Fig. 10-1 proposed by Bengio in 2003 consists of a one-hidden layer feed-forward neural network that predicts the next word in a sequence. The ML function of this model is:</p>
<p>$$ 
J_\theta = \frac{1}{T}\sum\limits_{t=1}^T\ \text{log} \space f(w_t , w_{t-1} , \cdots , w_{t-n+1})
$$ </p>
<p>After Bengio's first steps in neural language models, a lot of researches follows up training on a large vocabulary. We discuss them in the next section.</p>
<br />
<p style="font-size:18px; font-style:italic; font-weight:bold">2. Word Embedding</p>
<br>
<p>C&W</p>
<p>http://sebastianruder.com/word-embeddings-1/index.html#anoteonlanguagemodeling</p>
<br>
<p>Word2vec</p>
<br>
<p>Continuous bag-of-words</p>
<br>
<p>Skip-gram</p>

<br/>
<p style="font-size:18px; font-style:italic; font-weight:bold">3. Neural Converation Model</p>
<p>A basic sequence-to-sequence model, as introduced in Cho, consists of two recurrent neural networks (RNNs): an encoder that processes the input and a decoder that generates the output. This basic architecture is depicted below.
<p style="text-align:center"><img src="/collections/imgs/10-basic-seq2seq.png" style="width:800px;height:300px;" /></p>
<p style="text-align:center; font-style:italic; font-weight:bold">Fig. 10-2 Illustration of the seq2seq model</p>
Each box in the picture above represents a cell of the RNN, most commonly a GRU cell or an LSTM cell. Encoder and decoder can share weights or, as is more common, use a different set of parameters. Multi-layer cells have been successfully used in sequence-to-sequence models too, e.g. for translation Sutskever.
<p style="text-align:center"><img src="/collections/imgs/10-en_decoder.png" style="width:500px;height:600px;" /></p>
<p style="text-align:center; font-style:italic; font-weight:bold">Fig. 10-3 The context passed from encoder to decoder</p>
<p>In Fig. 10-3, every input has to be encoded into a fixed-size state vector \(C\), as that is the only thing passed to the decoder. To allow the decoder more direct access to the input, an attention mechanism was introduced in Bahdanau.</p>
<p style="text-align:center"><img src="/collections/imgs/10-attention.png" style="width:500px;height:500px;" /></p>
<p style="text-align:center; font-style:italic; font-weight:bold">Fig. 10-4 The alignment model of attention mechanism</p>
</p>
<p>We can train the seq2seq model end to end using back propagation. If we set the input as a large corpus of questions and the output as corresponding answers, we manage to build a chatbot model which can find a statistically most proper answer to the question being asked. However, we have to admit such dialogue system is far from the level of human converstation, the huge gap inbetween is the system cannot think like human do. To fill the gap, the next step received hot spot is dynamic neural network.</p>
<br />
<p style="font-size:24px; font-weight:bold">XI. Scrapy Redis</p>

<br />
<p style="font-size:24px; font-weight:bold">XII. Tensorflow, Theano and Caffe</p>

<br />
<p style="font-size:24px; font-weight:bold">XIII. Linear and Convex Optimzation</p>

<br />
<p style="font-size:24px; font-weight:bold">Appendix I. References</p>

<br />
<p style="font-size:24px; font-weight:bold">Appendix II. Resources</p>
