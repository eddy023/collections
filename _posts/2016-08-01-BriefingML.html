---
layout: default
title: Linear regression
---

<script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>

<p>The scientist’s discoveries impose his own order on chaos, as the composer or painter imposes his. — Arthur Koestler</p>

<p>I. Introduction</p>
<img src="/collections/imgs/1-ml-model.png" alt="basic ml model" style="width:400px;height:300px;" />
<p>The above figure shows the basic model of machine learning. We can express them using a simple math formula as:</p>
<p>$$ y = h(\sum_{i=0}^n \theta_i \times x_i) $$</p>
<p>\(x\) and \(y\) are the input and output data of this model, collected beforehand; \(h\) represents "hypothesis" and is partially embodied by \(theta_i\) which are the parameters to learn. For any known machine learning problem, people follow this basic model no matter how complicated their specific algorithm is.</p>

